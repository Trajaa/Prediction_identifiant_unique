{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a73bd23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Charger les données depuis le fichier CSV\n",
    "data = pd.read_csv('C:/Users/hp/Desktop/prj_pfe_inwi/data_overall.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a09b10e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mdn', 'idnt_client_crm', 'idnt_compte_facturation', 'desc_profil',\n",
      "       'princp_data_vol_jour_secteur', 'princp_data_vol_jour_ville',\n",
      "       'princp_data_vol_soir_secteur', 'princp_data_vol_soir_ville',\n",
      "       'princp_data_vol_nuit_secteur', 'princp_data_vol_nuit_ville',\n",
      "       'princp_data_vol_total_secteur', 'princp_data_vol_total_ville',\n",
      "       'princp_actv_total_secteur', 'princp_actv_ville'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Filtrer les colonnes catégorielles de type 'object'\n",
    "colonnes_categorielles = data.select_dtypes(include=['object'])\n",
    "\n",
    "# Afficher les colonnes catégorielles\n",
    "print(colonnes_categorielles.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3695cfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for colonne in colonnes_categorielles.columns:\n",
    "    # Encoder la variable catégorielle\n",
    "    encoded_variable = label_encoder.fit_transform(data[colonne])\n",
    "    # Assigner les valeurs encodées à la colonne correspondante dans la dataframe\n",
    "    data[colonne] = encoded_variable\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaaed4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mdn', 'idnt_client_crm', 'idnt_compte_facturation', 'desc_profil',\n",
      "       'princp_data_vol_jour_secteur', 'princp_data_vol_jour_ville',\n",
      "       'princp_data_vol_soir_secteur', 'princp_data_vol_soir_ville',\n",
      "       'princp_data_vol_nuit_secteur', 'princp_data_vol_nuit_ville',\n",
      "       'princp_data_vol_total_octets', 'princp_data_vol_total_secteur',\n",
      "       'princp_data_vol_total_ville', 'princp_actv_total_secteur',\n",
      "       'princp_actv_ville', 'princp_vol_actv'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f5a7a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['desc_profil',\n",
    "       'princp_data_vol_jour_secteur', 'princp_data_vol_jour_ville',\n",
    "       'princp_data_vol_soir_secteur', 'princp_data_vol_soir_ville',\n",
    "       'princp_data_vol_nuit_secteur', 'princp_data_vol_nuit_ville',\n",
    "       'princp_data_vol_total_octets', 'princp_data_vol_total_secteur',\n",
    "       'princp_data_vol_total_ville', 'princp_actv_total_secteur',\n",
    "       'princp_actv_ville', 'princp_vol_actv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12f2ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data[columns])\n",
    "data=data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0576f5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "953fbf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres à tester pour DBSCAN\n",
    "min_samples_values = [3,4,5,6, 7]  # Vous pouvez ajuster ces valeurs en fonction de votre taille de données\n",
    "eps_values = [0.5, 1.0, 1.5]    # Vous pouvez ajuster ces valeurs en fonction de votre échelle de données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8ad0ef5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs optimales :\n",
      "eps = 1.5\n",
      "min_samples = 6\n",
      "best_num_clusters = 4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "# Variables pour stocker les meilleures valeurs\n",
    "best_eps = None\n",
    "best_min_samples = None\n",
    "best_score = -1\n",
    "best_num_clusters = 0\n",
    "\n",
    "# Recherche des valeurs optimales\n",
    "for eps, min_samples in product(eps_values, min_samples_values):\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    clusters = dbscan.fit_predict(data_scaled)\n",
    "    \n",
    "    # Ignorer les résultats où tous les points sont considérés comme du bruit (-1)\n",
    "    if len(np.unique(clusters)) > 2:\n",
    "        num_clusters = len(np.unique(clusters)) - 1  # Soustraire 1 pour ne pas compter le bruit comme un cluster\n",
    "        if 3 <= num_clusters <= 10:\n",
    "            silhouette_avg = silhouette_score(data_scaled, clusters)\n",
    "            if silhouette_avg > best_score:\n",
    "                best_eps = eps\n",
    "                best_min_samples = min_samples\n",
    "                best_score = silhouette_avg\n",
    "                best_num_clusters = num_clusters\n",
    "\n",
    "# Affichage des valeurs optimales\n",
    "print(\"Valeurs optimales :\")\n",
    "print(\"eps =\", best_eps)\n",
    "print(\"min_samples =\", best_min_samples)\n",
    "print(\"best_num_clusters =\", best_num_clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3172af68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette moyenne: 0.07778769456625124\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Silhouette moyenne: {silhouette_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fccf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming you have already loaded or created the 'data' DataFrame and 'data_scaled' array.\n",
    "\n",
    "# Create and fit the DBSCAN model\n",
    "dbscan = DBSCAN(eps=best_eps, min_samples=best_min_samples)\n",
    "clusters = dbscan.fit_predict(data_scaled)\n",
    "\n",
    "# Convert clusters to integers (if needed)\n",
    "clusters = clusters.astype(int)\n",
    "\n",
    "# Verify the lengths of 'data' and 'clusters' match\n",
    "if len(data) == len(clusters):\n",
    "    # Add the 'cluster' column to the 'data' DataFrame\n",
    "    data['cluster'] = clusters\n",
    "else:\n",
    "    print(\"Error: 'data' and 'clusters' have different lengths.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085bb4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher le nombre de clusters créés et les échantillons dans chaque cluster\n",
    "num_clusters = len(set(clusters)) - (1 if -1 in clusters else 0)\n",
    "num_outliers = list(clusters).count(-1)\n",
    "print(\"Nombre de clusters : \", num_clusters)\n",
    "print(\"Nombre d'échantillons aberrants : \", num_outliers)\n",
    "\n",
    "# Afficher les données avec les clusters\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45676a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "\n",
    "# Paramètres de l'algorithme DBSCAN\n",
    "eps_values = [0.1, 0.5, 1.0]  # Valeurs à tester pour le rayon (epsilon)\n",
    "min_samples_values = [3, 5, 10]  # Valeurs à tester pour le nombre minimal d'échantillons\n",
    "\n",
    "best_silhouette_score = -1\n",
    "best_params = {}\n",
    "\n",
    "# Appliquer DBSCAN avec différentes combinaisons de paramètres\n",
    "for eps in eps_values:\n",
    "    for min_samples in min_samples_values:\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        dbscan.fit(data)\n",
    "        \n",
    "        # Calculer la silhouette score pour évaluer la qualité des clusters\n",
    "        silhouette_score = metrics.silhouette_score(data, dbscan.labels_)\n",
    "        \n",
    "        # Vérifier si le score est meilleur que le meilleur score précédent\n",
    "        if silhouette_score > best_silhouette_score:\n",
    "            best_silhouette_score = silhouette_score\n",
    "            best_params = {'eps': eps, 'min_samples': min_samples}\n",
    "\n",
    "# Afficher les paramètres optimaux et le meilleur score\n",
    "print(\"Meilleurs paramètres :\", best_params)\n",
    "print(\"Meilleur score silhouette :\", best_silhouette_score)\n",
    "\n",
    "# Appliquer DBSCAN avec les paramètres optimaux\n",
    "dbscan = DBSCAN(eps=best_params['eps'], min_samples=best_params['min_samples'])\n",
    "dbscan.fit(data)\n",
    "\n",
    "# Obtenir les étiquettes des clusters\n",
    "labels = dbscan.labels_\n",
    "\n",
    "# Nombre de clusters générés\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "print(\"Nombre de clusters générés :\", n_clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e00343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f050131e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a777d02c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60fcb468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "# Variables pour stocker les meilleures valeurs\n",
    "best_eps = None\n",
    "best_min_samples = None\n",
    "best_num_clusters = 0\n",
    "\n",
    "# Recherche des valeurs optimales\n",
    "for eps in np.arange(0.1, 1.0, 0.1):\n",
    "    for min_samples in range(2,10):\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        clusters = dbscan.fit_predict(data)\n",
    "        num_clusters = len(set(clusters)) - (1 if -1 in clusters else 0)\n",
    "        if num_clusters > best_num_clusters:\n",
    "            best_num_clusters = num_clusters\n",
    "            best_eps = eps\n",
    "            best_min_samples = min_samples\n",
    "\n",
    "# Affichage des valeurs optimales\n",
    "print(\"Valeurs optimales :\")\n",
    "print(\"eps =\", best_eps)\n",
    "print(\"min_samples =\", best_min_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99b40507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de clusters :  1421\n",
      "Nombre d'échantillons aberrants :  4181\n",
      "     mdn  idnt_client_crm  idnt_compte_facturation  desc_profil  \\\n",
      "0  18331            11280                    23208           61   \n",
      "1  36486            47493                    62695           61   \n",
      "2  55007            56871                    37150           46   \n",
      "3  57066            22474                    44784           61   \n",
      "4  23806            62522                    62455           36   \n",
      "\n",
      "   princp_data_vol_jour_secteur  princp_data_vol_jour_ville  \\\n",
      "0                         10160                          18   \n",
      "1                          5631                          18   \n",
      "2                         14717                          58   \n",
      "3                         10146                          18   \n",
      "4                          8963                          18   \n",
      "\n",
      "   princp_data_vol_soir_secteur  princp_data_vol_soir_ville  \\\n",
      "0                         10347                          22   \n",
      "1                             0                           0   \n",
      "2                             0                           0   \n",
      "3                         10329                          22   \n",
      "4                          4960                          22   \n",
      "\n",
      "   princp_data_vol_nuit_secteur  princp_data_vol_nuit_ville  \\\n",
      "0                          9689                          18   \n",
      "1                             0                           0   \n",
      "2                         13927                          64   \n",
      "3                             0                           0   \n",
      "4                         10768                          18   \n",
      "\n",
      "   princp_data_vol_total_octets  princp_data_vol_total_secteur  \\\n",
      "0                     19.786493                          11298   \n",
      "1                     16.820786                           6247   \n",
      "2                     22.386278                          16200   \n",
      "3                      7.113956                          11281   \n",
      "4                     20.039328                           5375   \n",
      "\n",
      "   princp_data_vol_total_ville  princp_actv_total_secteur  princp_actv_ville  \\\n",
      "0                           12                      11298                 12   \n",
      "1                           12                       6247                 12   \n",
      "2                           33                      16200                 33   \n",
      "3                           12                      11281                 12   \n",
      "4                           12                       5375                 12   \n",
      "\n",
      "   princp_vol_actv  cluster  \n",
      "0        19.786493        0  \n",
      "1        16.820786        1  \n",
      "2        22.386278        2  \n",
      "3         7.113956        0  \n",
      "4        20.039328       -1  \n"
     ]
    }
   ],
   "source": [
    "# Créer un objet DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=2)  # Réglez les paramètres eps et min_samples selon vos besoins\n",
    "\n",
    "# Effectuer le clustering\n",
    "clusters = dbscan.fit_predict(data_scaled)\n",
    "\n",
    "# Ajouter les résultats du clustering au jeu de données\n",
    "\n",
    "data['cluster'] = clusters\n",
    "\n",
    "# Afficher le nombre de clusters créés et les échantillons dans chaque cluster\n",
    "num_clusters = len(set(clusters)) - (1 if -1 in clusters else 0)\n",
    "num_outliers = list(clusters).count(-1)\n",
    "print(\"Nombre de clusters : \", num_clusters)\n",
    "print(\"Nombre d'échantillons aberrants : \", num_outliers)\n",
    "\n",
    "# Afficher les données avec les clusters\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd97afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Afficher le scatter plot 3D des résultats du clustering\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Données de clustering\n",
    "# Assurez-vous d'avoir les données 'data', les étiquettes de cluster 'clusters', et les colonnes 'columns' définies\n",
    "\n",
    "# Définir les couleurs pour chaque cluster\n",
    "colors = ['blue', 'red', 'green', 'orange', 'purple', 'yellow', 'cyan', 'magenta', 'lime', 'pink', 'brown', 'teal', 'lavender', 'olive', 'gold', 'salmon', 'lightblue', 'darkgreen', 'violet', 'lightgreen', 'coral', 'skyblue']\n",
    "\n",
    "# Obtenez la liste des étiquettes de cluster uniques\n",
    "cluster_labels = set(clusters)\n",
    "\n",
    "for cluster_label in cluster_labels:\n",
    "    if cluster_label == -1:\n",
    "        # Echantillons aberrants (outliers) sont affichés en noir\n",
    "        cluster_data = data[data['cluster'] == cluster_label][columns]\n",
    "        ax.scatter(cluster_data[columns[0]], cluster_data[columns[1]], cluster_data[columns[2]], color='black', alpha=0.5, label='Outliers')\n",
    "    else:\n",
    "        # Echantillons du cluster sont affichés dans une couleur spécifique\n",
    "        cluster_data = data[data['cluster'] == cluster_label][columns]\n",
    "        color_index = list(cluster_labels).index(cluster_label) % len(colors)\n",
    "        cluster_color = colors[color_index]\n",
    "        ax.scatter(cluster_data[columns[0]], cluster_data[columns[1]], cluster_data[columns[2]], color=cluster_color, alpha=0.5, label='Cluster {}'.format(cluster_label))\n",
    "\n",
    "ax.set_xlabel(columns[0])\n",
    "ax.set_ylabel(columns[1])\n",
    "ax.set_zlabel(columns[2])\n",
    "ax.set_title('DBSCAN Clustering')\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b491ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Afficher le scatter plot 3D des résultats du clustering\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Données de clustering\n",
    "# Assurez-vous d'avoir les données 'data', les étiquettes de cluster 'clusters', et les colonnes 'columns' définies\n",
    "\n",
    "# Définir les couleurs pour chaque cluster\n",
    "colors = ['blue', 'red', 'green', 'orange', 'purple', 'yellow', 'cyan', 'magenta', 'lime', 'pink', 'brown', 'teal', 'lavender', 'olive', 'gold', 'salmon', 'lightblue', 'darkgreen', 'violet', 'lightgreen', 'coral', 'skyblue']\n",
    "\n",
    "# Obtenez la liste des étiquettes de cluster uniques\n",
    "cluster_labels = set(clusters)\n",
    "\n",
    "for cluster_label in cluster_labels:\n",
    "    if cluster_label == -1:\n",
    "        # Echantillons aberrants (outliers) sont affichés en noir\n",
    "        cluster_data = data[data['cluster'] == cluster_label][columns]\n",
    "        ax.scatter(cluster_data[columns[3]], cluster_data[columns[4]], cluster_data[columns[2]], color='black', alpha=0.5, label='Outliers')\n",
    "    else:\n",
    "        # Echantillons du cluster sont affichés dans une couleur spécifique\n",
    "        cluster_data = data[data['cluster'] == cluster_label][columns]\n",
    "        color_index = list(cluster_labels).index(cluster_label) % len(colors)\n",
    "        cluster_color = colors[color_index]\n",
    "        ax.scatter(cluster_data[columns[3]], cluster_data[columns[4]], cluster_data[columns[2]], color=cluster_color, alpha=0.5, label='Cluster {}'.format(cluster_label))\n",
    "\n",
    "ax.set_xlabel(columns[3])\n",
    "ax.set_ylabel(columns[4])\n",
    "ax.set_zlabel(columns[2])\n",
    "ax.set_title('DBSCAN Clustering')\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c311f37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher le scatter plot 2D des résultats du clustering\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "colors = ['blue', 'red', 'green', 'orange', 'purple', 'yellow', 'cyan', 'magenta', 'lime', 'pink', 'brown', 'teal', 'lavender', 'olive', 'gold', 'salmon', 'lightblue']\n",
    " # Couleurs pour chaque cluster\n",
    "\n",
    "for cluster_label in set(clusters):\n",
    "    if cluster_label == -1:\n",
    "        # Echantillons aberrants (outliers) sont affichés en noir\n",
    "        cluster_data = data[data['cluster'] == cluster_label][columns]\n",
    "        plt.scatter(cluster_data[columns[0]], cluster_data[columns[1]], color='black', alpha=0.5, label='Outliers')\n",
    "    else:\n",
    "        # Echantillons du cluster sont affichés dans une couleur spécifique\n",
    "        cluster_data = data[data['cluster'] == cluster_label][columns]\n",
    "        plt.scatter(cluster_data[columns[0]], cluster_data[columns[1]], color=colors[cluster_label % len(colors)], alpha=0.5, label='Cluster {}'.format(cluster_label))\n",
    "\n",
    "plt.xlabel(columns[0])\n",
    "plt.ylabel(columns[1])\n",
    "plt.title('DBSCAN Clustering')\n",
    "\n",
    "# Afficher la légende\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
