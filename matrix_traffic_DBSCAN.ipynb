{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae9fb6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1:                                 a_number  a_own  \\\n",
      "0       805249d5353b56beffe265acb21d2922   True   \n",
      "1       805249d5353b56beffe265acb21d2922   True   \n",
      "2       805249d5353b56beffe265acb21d2922   True   \n",
      "3       805249d5353b56beffe265acb21d2922   True   \n",
      "4       805249d5353b56beffe265acb21d2922   True   \n",
      "...                                  ...    ...   \n",
      "199995  69061142d86f77340206b6cd9c3778a3   True   \n",
      "199996  62e48a886921108f43011b2ea85bcedb   True   \n",
      "199997  62e48a886921108f43011b2ea85bcedb   True   \n",
      "199998  62e48a886921108f43011b2ea85bcedb   True   \n",
      "199999  62e48a886921108f43011b2ea85bcedb   True   \n",
      "\n",
      "                                b_number  duration  duration_wh  \\\n",
      "0       c0cd71c4d34d274eca6aa7d3be7f66a4  9.223849     7.893572   \n",
      "1       f849a35b994ebbde78d26aa7e507a589  6.948897     6.047372   \n",
      "2       f7bbf080d6d62e98b98784957f31ee37  8.730852     7.926964   \n",
      "3       ca215256553a2ba6e75728c224658482  4.418841     0.000000   \n",
      "4       62a248714a24f84a59ab89a9e07866be  1.386294     1.386294   \n",
      "...                                  ...       ...          ...   \n",
      "199995  fd3a65eb37e5cfca54ff62a8641e02a2  3.912023     2.833213   \n",
      "199996  90962fe07cbdcdbfdf1ab56b9675e327  7.236339     6.699500   \n",
      "199997  215e2fdc742799e4bf065c6c81ea4091  5.081404     4.867534   \n",
      "199998  618782030f3394ef627a4252645dbe64  5.389072     5.298317   \n",
      "199999  b9fda053f6311c94f30fa3d26e83350d  1.945910     1.609438   \n",
      "\n",
      "        num_interactions  num_interactions_wh  num_interactions_sms  \\\n",
      "0               3.761200             2.484907              0.000000   \n",
      "1               2.833213             2.484907              0.693147   \n",
      "2               3.713572             2.833213              0.000000   \n",
      "3               0.693147             0.000000              0.000000   \n",
      "4               0.693147             0.693147              0.000000   \n",
      "...                  ...                  ...                   ...   \n",
      "199995          1.098612             0.693147              0.000000   \n",
      "199996          2.708050             1.791759              0.000000   \n",
      "199997          1.609438             1.386294              0.000000   \n",
      "199998          1.609438             0.693147              0.000000   \n",
      "199999          1.386294             1.098612              0.000000   \n",
      "\n",
      "        num_interactions_sms_wh  offnet  \n",
      "0                      0.000000       1  \n",
      "1                      0.693147       0  \n",
      "2                      0.000000       0  \n",
      "3                      0.000000       1  \n",
      "4                      0.000000       1  \n",
      "...                         ...     ...  \n",
      "199995                 0.000000       0  \n",
      "199996                 0.000000       1  \n",
      "199997                 0.000000       1  \n",
      "199998                 0.000000       1  \n",
      "199999                 0.000000       1  \n",
      "\n",
      "[200000 rows x 10 columns]\n",
      "data2:                                 a_number  a_own  \\\n",
      "200000  62e48a886921108f43011b2ea85bcedb   True   \n",
      "200001  62e48a886921108f43011b2ea85bcedb   True   \n",
      "200002  62e48a886921108f43011b2ea85bcedb   True   \n",
      "200003  62e48a886921108f43011b2ea85bcedb   True   \n",
      "200004  62e48a886921108f43011b2ea85bcedb   True   \n",
      "...                                  ...    ...   \n",
      "399995  41148a6474f9896e461718903fe50b7f   True   \n",
      "399996  41148a6474f9896e461718903fe50b7f   True   \n",
      "399997  41148a6474f9896e461718903fe50b7f   True   \n",
      "399998  41148a6474f9896e461718903fe50b7f   True   \n",
      "399999  41148a6474f9896e461718903fe50b7f   True   \n",
      "\n",
      "                                b_number  duration  duration_wh  \\\n",
      "200000  27c9d9c72c0b05840b2a90059085586a  1.945910     1.945910   \n",
      "200001  aade5572127296174948ae672365b5ee  0.000000     0.000000   \n",
      "200002  becaf18698dc3112d7dc4140ce77a185  0.000000     0.000000   \n",
      "200003  af515dfa290c61fd26791c3e5f62af02  1.098612     0.000000   \n",
      "200004  39acb69e06d4ea25e859ae05e5a7007f  6.766192     6.100319   \n",
      "...                                  ...       ...          ...   \n",
      "399995  2b53d9985585e47ea5e5ed7c1968e1da  8.490233     7.173192   \n",
      "399996  f48668cfe36998bdc3a95f4ba7dbfb42  0.000000     0.000000   \n",
      "399997  215e2fdc742799e4bf065c6c81ea4091  4.976734     4.976734   \n",
      "399998  9fde42a8669999936cdbdfb7911075a5  5.634790     5.634790   \n",
      "399999  c7e6c3eb27b3762c34b6f31aa19da2e1  0.693147     0.000000   \n",
      "\n",
      "        num_interactions  num_interactions_wh  num_interactions_sms  \\\n",
      "200000          0.693147             0.693147              0.000000   \n",
      "200001          2.197225             0.693147              2.197225   \n",
      "200002          0.693147             0.000000              0.693147   \n",
      "200003          0.693147             0.000000              0.000000   \n",
      "200004          1.945910             1.386294              0.000000   \n",
      "...                  ...                  ...                   ...   \n",
      "399995          2.890372             1.791759              1.098612   \n",
      "399996          1.098612             0.000000              1.098612   \n",
      "399997          1.386294             1.386294              0.000000   \n",
      "399998          1.791759             1.791759              0.000000   \n",
      "399999          0.693147             0.000000              0.000000   \n",
      "\n",
      "        num_interactions_sms_wh  offnet  \n",
      "200000                 0.000000       1  \n",
      "200001                 0.693147       1  \n",
      "200002                 0.000000       1  \n",
      "200003                 0.000000       1  \n",
      "200004                 0.000000       1  \n",
      "...                         ...     ...  \n",
      "399995                 0.000000       0  \n",
      "399996                 0.000000       1  \n",
      "399997                 0.000000       1  \n",
      "399998                 0.000000       1  \n",
      "399999                 0.000000       1  \n",
      "\n",
      "[200000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Charger les données depuis le fichier CSV\n",
    "data = pd.read_csv('C:/Users/hp/Desktop/prj_pfe_inwi/traffic_matrix.csv')\n",
    "def diviser_table(data):\n",
    "    n = len(data)\n",
    "    quart = n // 2  # Nombre d'éléments dans chaque sous-table\n",
    "\n",
    "    data1 = data[:quart]\n",
    "    data2 = data[quart:2*quart]\n",
    "\n",
    "    return data1, data2\n",
    "\n",
    "# Exemple d'utilisation\n",
    "\n",
    "data1, data2= diviser_table(data)\n",
    "\n",
    "# Afficher les sous-tables\n",
    "print(\"data1:\", data1)\n",
    "print(\"data2:\", data2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70524588",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data1[data1['a_own'] == True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe18e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['duration', 'duration_wh',\n",
    "       'num_interactions', 'num_interactions_wh', 'num_interactions_sms',\n",
    "       'num_interactions_sms_wh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e80dd35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['a_number', 'b_number'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Filtrer les colonnes catégorielles de type 'object'\n",
    "colonnes_categorielles = data.select_dtypes(include=['object'])\n",
    "\n",
    "# Afficher les colonnes catégorielles\n",
    "print(colonnes_categorielles.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fa4c5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12532\\1186893553.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[colonne] = encoded_variable\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12532\\1186893553.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[colonne] = encoded_variable\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for colonne in colonnes_categorielles.columns:\n",
    "    # Encoder la variable catégorielle\n",
    "    encoded_variable = label_encoder.fit_transform(data[colonne])\n",
    "    # Assigner les valeurs encodées à la colonne correspondante dans la dataframe\n",
    "    data[colonne] = encoded_variable\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da7c599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56263139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7e16716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres à tester pour DBSCAN\n",
    "min_samples_values = [3, 5, 7]  # Vous pouvez ajuster ces valeurs en fonction de votre taille de données\n",
    "eps_values = [0.5, 1.0, 1.5]    # Vous pouvez ajuster ces valeurs en fonction de votre échelle de données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "# Variables pour stocker les meilleures valeurs\n",
    "best_eps = None\n",
    "best_min_samples = None\n",
    "best_score = -1\n",
    "best_num_clusters = 0\n",
    "\n",
    "# Recherche des valeurs optimales\n",
    "for eps, min_samples in product(eps_values, min_samples_values):\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    clusters = dbscan.fit_predict(data_scaled)\n",
    "    \n",
    "    # Ignorer les résultats où tous les points sont considérés comme du bruit (-1)\n",
    "    if len(np.unique(clusters)) > 1:\n",
    "        num_clusters = len(np.unique(clusters)) - 1  # Soustraire 1 pour ne pas compter le bruit comme un cluster\n",
    "        if 3 <= num_clusters <= 10:\n",
    "            silhouette_avg = silhouette_score(data_scaled, clusters)\n",
    "            if silhouette_avg > best_score:\n",
    "                best_eps = eps\n",
    "                best_min_samples = min_samples\n",
    "                best_score = silhouette_avg\n",
    "                best_num_clusters = num_clusters\n",
    "\n",
    "# Affichage des valeurs optimales\n",
    "print(\"Valeurs optimales :\")\n",
    "print(\"eps =\", best_eps)\n",
    "print(\"min_samples =\", best_min_samples)\n",
    "print(\"best_num_clusters =\", best_num_clusters)\n",
    "\n",
    "print(f\"Silhouette moyenne: {silhouette_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec287388",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Appliquer DBSCAN avec les meilleures valeurs d'epsilon et de min_samples\n",
    "dbscan = DBSCAN(eps=best_eps, min_samples=best_min_samples)\n",
    "clusters = dbscan.fit_predict(data_scaled)\n",
    "\n",
    "# Ajouter les informations de cluster au DataFrame original\n",
    "data['cluster'] = clusters\n",
    "\n",
    "# Afficher le nombre de clusters créés et les échantillons dans chaque cluster\n",
    "num_clusters = len(set(clusters)) - (1 if -1 in clusters else 0)\n",
    "num_outliers = list(clusters).count(-1)\n",
    "print(\"Nombre de clusters : \", num_clusters)\n",
    "print(\"Nombre d'échantillons aberrants : \", num_outliers)\n",
    "\n",
    "# Afficher les données avec les clusters\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940109bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4afb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Afficher le scatter plot 3D des résultats du clustering\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Données de clustering\n",
    "# Assurez-vous d'avoir les données 'data', les étiquettes de cluster 'clusters', et les colonnes 'columns' définies\n",
    "\n",
    "# Définir les couleurs pour chaque cluster\n",
    "colors = ['blue', 'red', 'green', 'orange', 'purple', 'yellow', 'cyan', 'magenta', 'lime', 'pink', 'brown', 'teal', 'lavender', 'olive', 'gold', 'salmon', 'lightblue', 'darkgreen', 'violet', 'lightgreen', 'coral', 'skyblue']\n",
    "\n",
    "# Obtenez la liste des étiquettes de cluster uniques\n",
    "cluster_labels = set(clusters)\n",
    "\n",
    "for cluster_label in cluster_labels:\n",
    "    if cluster_label == -1:\n",
    "        # Echantillons aberrants (outliers) sont affichés en noir\n",
    "        cluster_data = data[data['cluster'] == cluster_label][columns]\n",
    "        ax.scatter(cluster_data[columns[0]], cluster_data[columns[1]], cluster_data[columns[2]], color='black', alpha=0.5, label='Outliers')\n",
    "    else:\n",
    "        # Echantillons du cluster sont affichés dans une couleur spécifique\n",
    "        cluster_data = data[data['cluster'] == cluster_label][columns]\n",
    "        color_index = list(cluster_labels).index(cluster_label) % len(colors)\n",
    "        cluster_color = colors[color_index]\n",
    "        ax.scatter(cluster_data[columns[0]], cluster_data[columns[1]], cluster_data[columns[2]], color=cluster_color, alpha=0.5, label='Cluster {}'.format(cluster_label))\n",
    "\n",
    "ax.set_xlabel(columns[0])\n",
    "ax.set_ylabel(columns[1])\n",
    "ax.set_zlabel(columns[2])\n",
    "ax.set_title('DBSCAN Clustering')\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740b1fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Afficher le scatter plot 3D des résultats du clustering\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Données de clustering\n",
    "# Assurez-vous d'avoir les données 'data', les étiquettes de cluster 'clusters', et les colonnes 'columns' définies\n",
    "\n",
    "# Définir les couleurs pour chaque cluster\n",
    "colors = ['blue', 'red', 'green', 'orange', 'purple', 'yellow', 'cyan', 'magenta', 'lime', 'pink', 'brown', 'teal', 'lavender', 'olive', 'gold', 'salmon', 'lightblue', 'darkgreen', 'violet', 'lightgreen', 'coral', 'skyblue']\n",
    "\n",
    "# Obtenez la liste des étiquettes de cluster uniques\n",
    "cluster_labels = set(clusters)\n",
    "\n",
    "for cluster_label in cluster_labels:\n",
    "    if cluster_label == -1:\n",
    "        # Echantillons aberrants (outliers) sont affichés en noir\n",
    "        cluster_data = data[data['cluster'] == cluster_label][columns]\n",
    "        ax.scatter(cluster_data[columns[3]], cluster_data[columns[4]], cluster_data[columns[2]], color='black', alpha=0.5, label='Outliers')\n",
    "    else:\n",
    "        # Echantillons du cluster sont affichés dans une couleur spécifique\n",
    "        cluster_data = data[data['cluster'] == cluster_label][columns]\n",
    "        color_index = list(cluster_labels).index(cluster_label) % len(colors)\n",
    "        cluster_color = colors[color_index]\n",
    "        ax.scatter(cluster_data[columns[3]], cluster_data[columns[4]], cluster_data[columns[2]], color=cluster_color, alpha=0.5, label='Cluster {}'.format(cluster_label))\n",
    "\n",
    "ax.set_xlabel(columns[3])\n",
    "ax.set_ylabel(columns[4])\n",
    "ax.set_zlabel(columns[2])\n",
    "ax.set_title('DBSCAN Clustering')\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1af34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher le scatter plot 2D des résultats du clustering\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "colors = ['blue', 'red', 'green', 'orange', 'purple', 'yellow', 'cyan', 'magenta', 'lime', 'pink', 'brown', 'teal', 'lavender', 'olive', 'gold', 'salmon', 'lightblue']\n",
    " # Couleurs pour chaque cluster\n",
    "\n",
    "for cluster_label in set(clusters):\n",
    "    if cluster_label == -1:\n",
    "        # Echantillons aberrants (outliers) sont affichés en noir\n",
    "        cluster_data = data[data['cluster'] == cluster_label][columns]\n",
    "        plt.scatter(cluster_data[columns[0]], cluster_data[columns[1]], color='black', alpha=0.5, label='Outliers')\n",
    "    else:\n",
    "        # Echantillons du cluster sont affichés dans une couleur spécifique\n",
    "        cluster_data = data[data['cluster'] == cluster_label][columns]\n",
    "        plt.scatter(cluster_data[columns[0]], cluster_data[columns[1]], color=colors[cluster_label % len(colors)], alpha=0.5, label='Cluster {}'.format(cluster_label))\n",
    "\n",
    "plt.xlabel(columns[0])\n",
    "plt.ylabel(columns[1])\n",
    "plt.title('DBSCAN Clustering')\n",
    "\n",
    "# Afficher la légende\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
